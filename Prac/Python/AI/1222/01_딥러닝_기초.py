# 딥러닝 (Deep Learning)
# 여러 층의 인공 신경망을 사용한 기계학습

# 특징
# 다층 구조로 복잡한 패턴 학습
# 특성 추출 자동화
# 대용량 데이터에서 강력한 성능

# 왜 딥??인가??
# 전통적 신경망:
# 입력 -> [은닉층 1개] -> 출력

# 딥러닝:
# 입력 -> [은닉층 1] -> [은닉층 2] -> [은닉층 3] ... [은닉층 N]  -> 출력

# 층이 깊다(Deep) = 많은 은닉층
# -> 더 복잡한 패턴 학습 가능


# 머신러닝 vs 딥러닝
# 머신 러닝
# 특성 추출: 사람이 직접 설계
# 데이터: 적은 양도 가능
# 해석: 비교적 쉬움
# 학습: 빠름

# 딥러닝:
# 특성 추출: 모델이 자동학습
# 데이터: 대용량 필요
# 해석: 어려움 (블랙박스)
# 학습: 느림(GPU 필요)

# 특성 추출 비교
# 이미지 분류 예시

# 머신러닝 방식:
# 전문가가 특성 설계 (모서리, 색상, 질감...)
# 특성 추출 알고리즘 적용
# 분류기 학습

# 딥러닝 방식:
# 이미지 입력
# 신경망이 자동으로 특성 학습
# 분류 결과 출력

# 딥러닝: End-to-End 학습


# 언제 무엇을 사용할까?

# 머신러닝 선택:
# 데이터가 적을 때 (수천 개)
# 해석이 중요할 때
# 컴퓨팅 자원 제한
# 정형 데이터 (테이블)

# 딥러닝 선택
# 데이터 많을 때 (수만 개 이상)
# 이미지, 텍스트, 음성 데이터
# GPU 사용 가능
# 최고 성능이 목표

# 딥러닝이 가능해진 이유
# 데이터(Data)
# 인터넷 폭발로 대용량 데이터

# 컴퓨터 파워
# GPU 병렬 처리
# 클라우드 컴퓨팅

# 주요 용어 정리
# 신경망 (Neural Network): 뇌의 뉴런을 모방한 계산 모델

# 층 (Layer): 신경망의 각 단계 (여러 뉴런의 집합)

# 가중치: 입력과 출력 사이의 연결 강도

# 파라미터: 학습을 통해 조정되는 값 (가중치 + 편향)

# 에폭 (Epoch): 전체 데이터를 한 번 학습하는 과정

# 배치 (Batch): 한 번에 처리하는 데이터 묶음

# GPU: 병렬 연산에 특화된 하드웨어

# PyTorch 설치 확인
import torch
import torchvision
print(torch.__version__)
print(f"Torchvision 버전: {torchvision.__version__}")

print(f"CUDA 사용 가능: {torch.cuda.is_available()}")

# 간단한 텐서 연산
x = torch.randn(3, 3)
print(f'텐서 생성 성공: \n{x}')
