# 활성화 함수 (Activation Function)

# 정의
# 뉴런의 출력을 결정하는 비선형 함수

# 역할
# 비선형성 도입
# 출력 범위 조절
# 신호 전달 여부 결정

# 왜 필요한가?
# 선형 함수만 사용하면
# 층1: y₁ = W₁x + b₁
# 층2: y₂ = W₂y₁ + b₂
#      = W₂(W₁x + b₁) + b₂
#      = (W₂W₁)x + (W₂b₁ + b₂)
#      = W'x + b'

# 아무리 층을 쌓아도 단일 선형 변환!
# 비선형 함수가 있어야 복잡한 패턴 학습 가능
