# 미분
# 미분 = 순간적인 변화율

# 일상 예시:
# 자동차 속도계
# - 현재 속도 = 위치의 순간 변화율

# 평균 변화율 vs 순간 변화율
# 평균 변화율
# 서울 -> 부산 400km, 4시간 소요
# 평균 속도 = 400km/4h = 100km/h

# 순간 변화율(미분):
# - 특정 순간의 속도
# - 속도계가 보여주는 값
# - 시간 간격을 극한으로 줄임

# 기하학적 의미
# 미분 = 그래프에서 접선의 기울기

# y = x² 그래프에서:
# x=2에서 접선 기울기 = 4
# x=0에서 접선 기울기 = 0
# x=-2에서 접선 기울기 = -4

# 기본 미분 공식  

# 미분 표기법 
# y = f(x) 일때, 미분을 표현하는 방법:
# f'(x) <- 프라임 표기
# dy/dx <- 라이프니츠 표기
# d/dx f(x) <- 미분 연산자

# 기본 공식
# 상수의 미분
# f(x) = 5
# f'(x) = 0

# 거듭 제곱의 미분
# f(x) = x^n
# f'(x) = n * x^(n-1)

# 덧셈 법칙:
# (f + g)' = f' + g'

# f(x) = x² + x³
# f'(x) = 2x + 3x²


# 상수배 법칙:
# (c x f)' = c x f'
# f(x) = 3x²
# f'(x) = 3 × 2x = 6x


# 편미분
# 여러 변수가 있을 때, 하나만 변화시키고
# 나머지는 고정한 채로 미분

# f(x, y) = x² + y²

# x에 대한 편미분: ∂f/∂x = 2x (y는 상수 취급)
# y에 대한 편미분: ∂f/∂y = 2y (x는 상수 취급)

# ∂ (편미분 기호, '파셜' 또는 '델'이라고 읽음)
# ∂f/∂x = f를 x로 편미분


# AI에서 미분의 역할
# 손실 함수와 미분
# AI 학습의 핵심:
# 손실(오차)을 최소화하는 방향을 가중치를 조정

# 손실 함수를 가중치로 미분
# - 손실이 감소하는 방향을 알 수 있음
# - 그 방향으로 가중치 업데이트


# 그래디언트
# 모든 편미분을 벡터로 모은 것
# f(x,y) = x² + y² 일 때:
# 그래디언트 = [∂f/∂x, ∂f/∂y]
#           = [2x, 2y]

# (3, 4)에서 그래디언트 = [6, 8]

# 의미: 함수가 가장 급격히 증가하는 방향
# (반대 방향) = 가장 급격히 감소하는 방향

#  경사 하강법, 연쇄 법칙


# 경사 하강법 
# 현재 위치에서 가장 경사가 급한 방향 확인
# 그 방향으로 한걸음 이동
# 반복 -> 결국 가장 낮은 곳에 도착

# AI
# 현재 손실에서 그래디언트 계산
# 손실이 줄어드는 방향으로 가중치를 조정
# 반복 -> 최소 손실에 도달



# 수학적 표현
# 목표: f(x)를 최소로 만드는 x 찾기
# 경상 하강법:
# x_new = x_old - η × f'(x_old)

# η (eta) = 학습률 (learning rate)
# f'(x) = 기울기 (그래디언트)

# 기울기가 양수 (+) -> 오른쪽으로 가면 증가
#                   -> 왼쪽으로 가야 감소
#                   -> 빼기 사용

# 기울기가 음수 (-) -> 왼쪽으로 가면 증가
#                   -> 오른쪽으로 가야 감소
#                   -> 빼기 사용

# 결론 : 항상 기울기를 빼면 최솟값 방향으로 이동!

# 학습률 (learning Rate)
# 학습률 = 한 번에 얼마나 크게 이동할지 결정
# η = 0.001 => 아주 작은 걸음(느리지만 안정적)
# η = 0.1 => 적당한 걸음
# η = 1.0 => 큰 걸음(빠르지만 불안정)

# 일반적인 시작점:
# η = 0.001 ~ 0.1 사이에서 시작하여 실험적으로 조정

# 실제 예제 코드
import numpy as np

# 목표 함수: f(x) = x²
# 미분: f'(x) = 2x
# 목표: x²을 최소화하는 x 찾기 (정답: x=0)

def f(x):
    return x**2

def df(x):  # 미분 함수
    return 2*x

# 경사 하강법 실행
x = 10.0  # 시작점
학습률 = 0.1
반복횟수 = 20

print("경사 하강법으로 최솟값 찾기")
print(f"시작점: x = {x}, f(x) = {f(x)}")

for i in range(반복횟수):
    기울기 = df(x)
    x = x - 학습률 * 기울기  # 경사 하강법 공식
    print(f"반복 {i+1}: x = {x:.4f}, f(x) = {f(x):.4f}, 기울기 = {기울기:.4f}")

print(f"\n최종 결과: x = {x:.4f}, f(x) = {f(x):.6f}")

# 핵심 정리
# 1. 미분 = 순간 변화율 = 접선의 기울기
# 2. 편미분: 여러 변수 중 하나만 변화시키며 미분
# 3. 그래디언트: 모든 편미분을 벡터로 모은 것
# 4. 경사 하강법: 그래디언트의 반대 방향으로 이동하여 최솟값 찾기
# 5. 학습률: 이동 보폭 조절 (너무 크면 불안정, 너무 작으면 느림)
# 6. AI 학습 = 경사 하강법으로 손실 함수를 최소화하는 과정
