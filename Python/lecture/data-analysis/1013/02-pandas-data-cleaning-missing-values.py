import pandas as pd
import numpy as np

# ═══════════════════════════════════════════════════════════════
# 데이터 정제 (Data Cleaning)
# ═══════════════════════════════════════════════════════════════
# 실제 현업에서 수집한 데이터는 완벽하지 않습니다.
# 데이터 분석의 80%는 데이터 정제 작업이라고 할 정도로 중요한 과정입니다.

# ─────────────────────────────────────────────────────────────
# 1. 현실의 "더러운 데이터" 예시
# ─────────────────────────────────────────────────────────────

dirty_data = pd.DataFrame({
    # 중복된 이름, 결측값(None) 존재
    'name': ['John Doe', 'Jane Smith', 'John Doe', 'Jane Smith', None, 'Bob Wilson'],

    # 형식 불일치: 숫자, 문자열, None 혼재 / 이상값: 250살
    'age': ['25', '30 years', 28, 'thirty', None, 250],

    # 중복 이메일, 형식 오류(@뒤 도메인 누락), None
    'email': ['john@email.com', 'jane@email', 'john@email.com',
              'jane@email.com', 'invalid@', None],

    # 날짜 형식이 제각각: YYYY-MM-DD, YYYY.MM.DD, MM/DD/YYYY 혼재
    # 날짜 오류: 13월 45일은 존재하지 않음
    'join_date': ['2024-01-01', '2024.01.15', '01/20/2024',
                  '2024-01-15', None, '2024-13-45']
})

print(dirty_data)

'''
    데이터 품질 문제점:
    1. 중복 데이터 - 동일한 사람이 여러 번 기록됨
    2. 결측값 - None, NaN 등 비어있는 데이터
    3. 형식 불일치 - age가 숫자/문자 혼재, 날짜 형식 다양
    4. 이상값 - age가 250살처럼 비현실적인 값
    5. 무결성 위반 - 존재할 수 없는 날짜(13월 45일)
'''

# ═══════════════════════════════════════════════════════════════
# 결측값 (Missing Values)
# ═══════════════════════════════════════════════════════════════
# 비어있는, 알 수 없는, 기록되지 않은 데이터를 의미합니다.

'''
    결측값의 종류와 표현 방식:
    
    1. None - Python의 기본 빈 객체
       - 객체형(object) 데이터에 주로 사용
       - 예: 문자열 컬럼의 결측값
    
    2. np.nan (Not a Number) - NumPy의 결측값 표현
       - 숫자형 데이터에 주로 사용
       - 수학 연산에서 nan 전파 (nan + 1 = nan)
    
    3. pd.NA - Pandas의 범용 결측값 (최신 버전)
       - 모든 데이터 타입에 사용 가능
       - Boolean 연산 개선
    
    4. 빈 문자열 - '', " " (공백)
       - 기술적으로는 결측값이 아니지만 의미 없는 데이터
       - 명시적으로 처리 필요
    
    5. 특수 값 - -999, 99999, -1 등
       - 도메인 지식에 따라 결측값으로 처리해야 할 수 있음
       - 예: 나이 -999는 실제로는 결측값을 의미
'''

# 다양한 결측값 타입 예시
missing_types = pd.DataFrame({
    'none_type': [1, 2, None, 4],           # Python None
    'nan_type': [1, 2, np.nan, 4],          # NumPy NaN (숫자형 결측값)
    'empty_string': ['A', 'B', '', 'D'],    # 빈 문자열 (결측값 아님!)
    'whitespace': ['A', 'B', ' ', 'D'],     # 공백 (결측값 아님!)
    'special_value': [1, 2, -999, 4]        # 특수 값 (도메인에 따라 결측값 처리)
})

print(missing_types)

# ─────────────────────────────────────────────────────────────
# 2. 결측값 탐지 (Detection)
# ─────────────────────────────────────────────────────────────

# isna() / isnull() - 결측값이면 True 반환
# 두 메서드는 완전히 동일한 기능 (isna가 더 최신 권장)
print('=== isna() ===')
print(missing_types.isna())    # 결측값 위치를 True/False로 표시
print(missing_types.isnull())  # isna()와 동일
print()

# notna() / notnull() - 값이 있으면 True 반환 (isna의 반대)
print('=== notna() ===')
print(missing_types.notna())   # 값이 있는 위치를 True로 표시
print(missing_types.notnull())  # notna()와 동일

# ─────────────────────────────────────────────────────────────
# 3. 결측값 통계 확인
# ─────────────────────────────────────────────────────────────

# 열별 결측값 개수 계산
# .isna()로 True/False 생성 → .sum()으로 True 개수 집계
print('=== 열별 결측값 개수 ===')
print(missing_types.isna().sum())
# 결과:
# none_type        1  (3번 행에 None)
# nan_type         1  (3번 행에 NaN)
# empty_string     0  (빈 문자열은 결측값으로 인식 안 됨)
# whitespace       0  (공백도 결측값으로 인식 안 됨)
# special_value    0  (-999는 실제 숫자로 인식)

# 전체 결측값 개수 (모든 열의 결측값 합계)
print('전체 결측값:', missing_types.isna().sum().sum())
# .sum() 첫 번째: 각 열의 결측값 개수
# .sum() 두 번째: 그 개수들의 합

# ═══════════════════════════════════════════════════════════════
# 결측값 처리 전략
# ═══════════════════════════════════════════════════════════════

'''
    결측값 처리 3가지 주요 전략:
    
    1. 삭제 (Deletion)
       - 결측값이 있는 행/열 제거
       - 장점: 간단하고 빠름
       - 단점: 데이터 손실, 샘플 수 감소
       - 사용 시기: 결측값이 소수이고 무작위일 때
    
    2. 대체 (Imputation)
       - 통계값(평균, 중앙값, 최빈값)으로 채우기
       - 장점: 데이터 보존
       - 단점: 편향 발생 가능
       - 사용 시기: 결측값이 일정 패턴 없이 분포할 때
    
    3. 예측 (Prediction)
       - 앞뒤 값이나 다른 변수로 추정
       - 장점: 정확도 높음
       - 단점: 복잡함
       - 사용 시기: 시계열 데이터, 결측값이 많을 때
'''

# ─────────────────────────────────────────────────────────────
# 4. 결측값 처리 실습용 샘플 데이터
# ─────────────────────────────────────────────────────────────

sales_data = pd.DataFrame({
    # 2024년 1월 1일부터 7일간의 날짜
    'date': pd.date_range('2024-01-01', periods=7),

    # 매출: 3번, 5번 행에 결측값
    'sales': [100, 120, np.nan, 150, np.nan, 180, 200],

    # 고객수: 4번 행에 결측값
    'customers': [20, 25, 22, np.nan, 30, 35, 40],

    # 지역: 3번, 6번 행에 결측값
    'region': ['Seoul', 'Busan', np.nan, 'Daegu', 'Seoul', np.nan, 'Busan']
})

print('=== 원본 데이터 ===')
print(sales_data)
print()

# ─────────────────────────────────────────────────────────────
# 전략 1: 삭제 (Deletion)
# ─────────────────────────────────────────────────────────────

# 1-1. 결측값이 있는 행 전체 삭제
# dropna(): 결측값이 하나라도 있는 행을 모두 제거
drop_rows = sales_data.dropna()
print('결측값이 있는 행 삭제:')
print(drop_rows)
# 결과: 7개 행 중 결측값 없는 0, 1, 6번 행만 남음 (3개 행만 유지)
# 주의: 데이터가 대폭 줄어듦!
print()

# 1-2. 결측값이 있는 열 전체 삭제
# axis=1: 열(column) 방향으로 삭제
drop_cols = sales_data.dropna(axis=1)
print('결측값이 있는 열 삭제:')
print(drop_cols)
# 결과: sales, customers, region 열이 모두 삭제됨
# date 열만 남음 (날짜 정보만으로는 분석 불가!)
print()

# 1-3. 특정 열 기준으로만 삭제
# subset=['sales']: sales 열에 결측값이 있는 행만 삭제
drop_sales = sales_data.dropna(subset=['sales'])
print('sales 열 기준으로만 삭제:')
print(drop_sales)
# 결과: sales가 NaN인 3번, 5번 행만 제거됨
# customers, region의 결측값은 무시됨
print()

# ─────────────────────────────────────────────────────────────
# 전략 2: 대체 (Imputation) - 통계값 사용
# ─────────────────────────────────────────────────────────────

# 2-1. 평균값으로 대체
# 주의: 원본 데이터를 보존하기 위해 .copy() 사용!
fill_mean = sales_data.copy()
# fillna(평균값): 결측값을 평균으로 채움
fill_mean['sales'] = fill_mean['sales'].fillna(fill_mean['sales'].mean())
print('평균값으로 대체:')
print(fill_mean)
# sales 평균: (100+120+150+180+200) / 5 = 150
# 3번, 5번 행의 NaN → 150으로 채워짐
print()

# 2-2. 중앙값으로 대체 (이상값이 있을 때 유용!)
# median(): 데이터를 정렬했을 때 중간 값
fill_median = sales_data.copy()
fill_median['sales'] = fill_median['sales'].fillna(
    fill_median['sales'].median()
)
print('중앙값으로 대체:')
print(fill_median)
# sales 중앙값: [100, 120, 150, 180, 200] 정렬 → 중간값 150
# 평균과 달리 극단값(outlier)의 영향을 덜 받음
# 예: 데이터가 [100, 120, 150, 180, 10000]이면
#     평균 = 2110 (왜곡됨)
#     중앙값 = 150 (안정적)
print()

# ─────────────────────────────────────────────────────────────
# 전략 3: 시계열 대체 (Time Series Imputation)
# ─────────────────────────────────────────────────────────────
# 시간 순서가 있는 데이터에서 앞뒤 값으로 결측값을 채웁니다.
# 주가, 온도, 판매량처럼 연속적인 패턴이 있는 데이터에 적합합니다.

# 3-1. Forward Fill (앞의 값으로 채우기)
# method='ffill': 결측값 바로 이전 값으로 채움
fill_forward = sales_data.copy()
fill_forward['customers'] = fill_forward['customers'].fillna(method='ffill')
print('Forward Fill (앞 값으로 채우기):')
print(fill_forward)
# customers 4번 행 NaN → 3번 행의 22로 채워짐
# 논리: "어제 고객수가 22명이었으면 오늘도 비슷할 것"
print()

# 3-2. Backward Fill (뒤의 값으로 채우기)
# method='bfill': 결측값 바로 다음 값으로 채움
fill_backward = sales_data.copy()
fill_backward['customers'] = fill_backward['customers'].fillna(
    method='bfill'
)
print('Backward Fill (뒤 값으로 채우기):')
print(fill_backward)
# customers 4번 행 NaN → 5번 행의 30으로 채워짐
# 논리: "내일 고객수가 30명이면 오늘도 비슷할 것"
print()

# ═══════════════════════════════════════════════════════════════
# 실전 예제: 환경 데이터 정제
# ═══════════════════════════════════════════════════════════════

data = {
    "도시": ["서울", "부산", "광주", "대구", np.nan, "춘천"],
    "미세먼지": [45, 51, np.nan, 38, 49, np.nan],         # PM10
    "초미세먼지": [20, np.nan, 17, 18, 22, 19],           # PM2.5
    "강수량": [0.0, 2.5, 1.0, np.nan, 3.1, 0.0]          # mm
}

df = pd.DataFrame(data)

print('=== 환경 데이터 원본 ===')
print(df)
print()

# 결측값 현황 파악
print('=== 결측값 개수 ===')
print(df.isna().sum())
print()

# 처리 전략 수립:
# 1. 도시명 결측 → 삭제 (도시를 모르면 데이터 무의미)
# 2. 미세먼지 결측 → 평균값 대체 (대기질은 인근 지역과 유사)
# 3. 초미세먼지 결측 → 중앙값 대체 (극단값 영향 최소화)
# 4. 강수량 결측 → 0으로 대체 (기록 없음 = 비 안 옴)

# 1. 도시명 결측 행 제거
df_clean = df.dropna(subset=['도시'])
print('=== 도시명 결측 제거 후 ===')
print(df_clean)
print()

# 2. 미세먼지 평균값으로 대체
pm10_mean = df_clean['미세먼지'].mean()  # (45+51+38+49)/4 = 45.75
df_clean['미세먼지'] = df_clean['미세먼지'].fillna(pm10_mean)
print('=== 미세먼지 평균 대체 후 ===')
print(df_clean)
print()

# 3. 초미세먼지 중앙값으로 대체
pm25_median = df_clean['초미세먼지'].median()  # [17, 18, 20, 22] → 19
df_clean['초미세먼지'] = df_clean['초미세먼지'].fillna(pm25_median)
print('=== 초미세먼지 중앙값 대체 후 ===')
print(df_clean)
print()

# 4. 강수량 0으로 대체
df_clean['강수량'] = df_clean['강수량'].fillna(0)
print('=== 최종 정제 데이터 ===')
print(df_clean)
print()

# 최종 결측값 확인
print('=== 최종 결측값 확인 ===')
print(df_clean.isna().sum())
# 모든 결측값이 처리되어야 함!

'''
═══════════════════════════════════════════════════════════════
결측값 처리 의사결정 가이드
═══════════════════════════════════════════════════════════════

┌──────────────────┬─────────────────┬──────────────────┐
│ 상황             │ 권장 방법        │ 이유             │
├──────────────────┼─────────────────┼──────────────────┤
│ 식별자 결측      │ 삭제            │ 행 추적 불가     │
│ 결측 <5%        │ 삭제            │ 영향 미미        │
│ 결측 5-40%      │ 평균/중앙값 대체│ 데이터 보존      │
│ 결측 >40%       │ 열 삭제 고려    │ 신뢰도 낮음      │
│ 시계열 데이터    │ ffill/bfill    │ 연속성 유지      │
│ 범주형 데이터    │ 최빈값 대체     │ 가장 흔한 값     │
│ 이상값 존재      │ 중앙값 대체     │ 평균 왜곡 방지   │
└──────────────────┴─────────────────┴──────────────────┘

주의사항:
- 결측값 처리 전 반드시 원본 백업 (.copy() 사용)
- 처리 이유를 문서화 (재현 가능성)
- 도메인 지식 활용 (통계만으로 판단 금지)
- 여러 방법 시도 후 결과 비교
'''

print()
print()
